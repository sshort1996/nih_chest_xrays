{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIH data CNN notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import streamlit as st\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "from array import array\n",
    "from os.path  import join\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNN.preprocess as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created test and training directories\n",
      "train_set: 4484 elements\n",
      "test_set: 1122 elements\n",
      "parsing csv\n"
     ]
    }
   ],
   "source": [
    "pp.train_test_split_images(root_dir: str, training_fraction: float)\n",
    "pp.train_test_split_labels(root_dir: str, train_set: List[int], test_set: List[int])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emphysema detector Network\n",
    "Let's try a network to detect emphysema cxr's first, baby steps.\n",
    "\n",
    "We'll make another copy of the `test_nih` and `training_nih` directories and remove all the other conditions from the `labels.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.filter_emphysema_rows(join('data', 'sample_labels.csv'), join('data', 'emph_labels.csv'))\n",
    "pp.filter_emphysema_rows(join('data', 'test_nih', 'labels.csv'), join('data', 'test_nih', 'emph_labels.csv'))\n",
    "pp.filter_emphysema_rows(join('data', 'training_nih', 'labels.csv'), join('data', 'training_nih', 'emph_labels.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from array import array\n",
    "\n",
    "\n",
    "# MNIST Data Loader Class\n",
    "class NIHDataloader(object):\n",
    "    def __init__(self, \n",
    "                training_images_filepath,\n",
    "                training_labels_filepath,\n",
    "                test_images_filepath, \n",
    "                test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "\n",
    "    def read_labels(self, labels_filepath):        \n",
    "        labels = []\n",
    "        images = []\n",
    "        \n",
    "        with open(labels_filepath, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            labels = array(\"B\", [1 if row[1]==\"true\" else 0 for row in reader])   \n",
    "        \n",
    "        return labels\n",
    "\n",
    "    def read_images(self, images_filepath):        \n",
    "        labels = []\n",
    "        images = []\n",
    "                        \n",
    "        # Get the list of image file paths in the directory\n",
    "        image_paths = glob.glob(os.path.join(images_filepath, \"*.png\"))\n",
    "\n",
    "        # Iterate over each image path\n",
    "        for image_path in image_paths:\n",
    "            image = Image.open(image_path)\n",
    "            resized_image = image.resize((512, 512))\n",
    "            grayscale_image = resized_image.convert(\"L\")\n",
    "            # array = np.array(grayscale_image).astype(float)\n",
    "            array = np.array(grayscale_image).astype(np.float16)\n",
    "\n",
    "            images.append(array)\n",
    "\n",
    "        return images\n",
    "        \n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train = self.read_images(self.training_images_filepath)\n",
    "        y_train = self.read_labels(self.training_labels_filepath)\n",
    "        x_test = self.read_images(self.training_images_filepath)\n",
    "        y_test = self.read_labels(self.training_labels_filepath)\n",
    "\n",
    "          # Convert data to NumPy arrays\n",
    "        x_train = np.array(x_train)\n",
    "        y_train = np.array(y_train)\n",
    "        x_test = np.array(x_test)\n",
    "        y_test = np.array(y_test)\n",
    "        \n",
    "        return (x_train, y_train),(x_test, y_test)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data ingestion methods\n",
    "Let's decide which of our labels we want to train for first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths based on added MNIST Datasets``\n",
    "input_path = 'data'\n",
    "training_images_filepath = join(input_path, join('training_nih', 'images'))\n",
    "training_labels_filepath = join(input_path, join('training_nih', 'emph_labels.csv'))\n",
    "test_images_filepath = join(input_path, join('test_nih', 'images'))\n",
    "test_labels_filepath = join(input_path, join('test_nih', 'emph_labels.csv'))\n",
    "\n",
    "# Load MINST dataset\n",
    "nih_dataloader = NIHDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = nih_dataloader.read_images(training_images_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = nih_dataloader.read_labels(training_labels_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images[0]: [[ 2.  2.  2. ...  1.  1.  1.]\n",
      " [ 3.  5.  4. ...  4.  2.  1.]\n",
      " [ 2.  5.  5. ...  5.  2.  1.]\n",
      " ...\n",
      " [ 2.  3.  3. ... 63. 74. 28.]\n",
      " [ 2.  3.  3. ... 58. 74. 30.]\n",
      " [ 1.  2.  2. ... 27. 36. 15.]]\n",
      "labels[0]: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'images[0]: {images[1]}')\n",
    "print(f'labels[0]: {labels[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(labels): <class 'array.array'>\n",
      "type(labels[1]): <class 'int'>\n",
      "labels[1]: 1\n",
      "len(labels): 4484\n"
     ]
    }
   ],
   "source": [
    "print(f'type(labels): {type(labels)}')\n",
    "print(f'type(labels[1]): {type(labels[1])}')\n",
    "print(f'labels[1]: {labels[1]}')\n",
    "print(f'len(labels): {len(labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building CNN model\n",
    "Helper functions to manage model building, training and training analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def compile_model(learning_rate: float):\n",
    "    # Setting up the convolution neural network with convnet and maxpooling layer\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(512, 512, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "    # Model Summary\n",
    "    print(f'model.summary(): {model.summary()}')\n",
    "\n",
    "    # Adding the fully connected layers to CNN\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    # Printing model summary\n",
    "    print(f'model.summary(): {model.summary()}')\n",
    "\n",
    "    # Create the optimizer with a new learning rate\n",
    "    optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    # Configuring the network with the custom optimizer\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    # # Configuring the network\n",
    "    # model.compile(optimizer='rmsprop(lr=0.0025)',\n",
    "    #             loss='binary_crossentropy',\n",
    "    #             metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(X_train, Y_train, X_test, Y_test, model, epochs, batch_size):\n",
    "    history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = precision_score(Y_test, y_pred)\n",
    "    recall = recall_score(Y_test, y_pred)\n",
    "    f1 = f1_score(Y_test, y_pred)\n",
    "\n",
    "    return history, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras metrics callback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, x_test, y_test):\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(\"Training started...\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Predict on test set\n",
    "        y_pred = self.model.predict(self.x_test)\n",
    "        y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "        # Calculate precision, recall, and F1 score\n",
    "        precision = precision_score(self.y_test, y_pred)\n",
    "        recall = recall_score(self.y_test, y_pred)\n",
    "        f1 = f1_score(self.y_test, y_pred)\n",
    "\n",
    "        # Print the metrics\n",
    "        print(f\"Epoch {epoch+1}/{self.params['epochs']}\")\n",
    "        print(f\"loss: {logs['loss']}, accuracy: {logs['accuracy']}, precision: {precision}, recall: {recall}, f1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.19 GiB for an array with shape (4484, 512, 512) and data type float16",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n\u001b[0;32m      3\u001b[0m metrics_callback \u001b[39m=\u001b[39m MetricsCallback(x_test, y_test)\n\u001b[1;32m----> 4\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, callbacks\u001b[39m=\u001b[39;49m[metrics_callback])\n\u001b[0;32m      6\u001b[0m \u001b[39m# history, precision, recall, f1 = train_model(x_train, y_train, x_test, y_test, model, 32, 32)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[39m# print('train model')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:86\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Converts the given `value` to an `EagerTensor`.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[39mNote that this function could return cached copies of created constants for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39m  TypeError: if `dtype` is not compatible with the type of t.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m     83\u001b[0m   \u001b[39m# Make a copy explicitly because the EagerTensor might share the underlying\u001b[39;00m\n\u001b[0;32m     84\u001b[0m   \u001b[39m# memory with the input array. Without this copy, users will be able to\u001b[39;00m\n\u001b[0;32m     85\u001b[0m   \u001b[39m# modify the EagerTensor after its creation by changing the input array.\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m   value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, ops\u001b[39m.\u001b[39mEagerTensor):\n\u001b[0;32m     88\u001b[0m   \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m dtype:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.19 GiB for an array with shape (4484, 512, 512) and data type float16"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "batch_size = 32\n",
    "metrics_callback = MetricsCallback(x_test, y_test)\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[metrics_callback])\n",
    "\n",
    "# history, precision, recall, f1 = train_model(x_train, y_train, x_test, y_test, model, 32, 32)\n",
    "\n",
    "# print('train model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "We're getting serious overfitting in the model above, lets take the minority category  in the training dataset and apply rotations, and mirroring. We'll exclude scaling and cropping for now since the images are all pretty tight on the torso.\n",
    "\n",
    "Here's the data ingestion methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from array import array\n",
    "\n",
    "\n",
    "# MNIST Data Loader Class\n",
    "class NIHDataloader(object):\n",
    "    def __init__(self, \n",
    "                training_images_filepath,\n",
    "                training_labels_filepath,\n",
    "                test_images_filepath, \n",
    "                test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "\n",
    "    def read_labels(self, labels_filepath):        \n",
    "        labels = []\n",
    "        images = []\n",
    "        \n",
    "        with open(labels_filepath, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            labels = array(\"B\", [1 if row[1]==\"true\" else 0 for row in reader])   \n",
    "        \n",
    "        return labels\n",
    "\n",
    "    def read_images(self, images_filepath):        \n",
    "        labels = []\n",
    "        images = []\n",
    "                        \n",
    "        # Get the list of image file paths in the directory\n",
    "        image_paths = glob.glob(os.path.join(images_filepath, \"*.png\"))\n",
    "\n",
    "        # Iterate over each image path\n",
    "        for image_path in image_paths:\n",
    "            image = Image.open(image_path)\n",
    "            resized_image = image.resize((512, 512))\n",
    "            grayscale_image = resized_image.convert(\"L\")\n",
    "            # array = np.array(grayscale_image).astype(float)\n",
    "            array = np.array(grayscale_image).astype(np.float16)\n",
    "\n",
    "            images.append(array)\n",
    "\n",
    "        return images\n",
    "        \n",
    "    def augmented_training_images(self, training_filepath: str):\n",
    "        \"\"\"\n",
    "        Function to augment minority category of training data to be of equal size to majority category\n",
    "\n",
    "        Steps: \n",
    "            - ingest training images and labels from new data subdir\n",
    "            for each image in training set (while len(cat A)<len(cat B))\n",
    "            - create new unique id\n",
    "            - write row to label csv\n",
    "            - apply one of a set of transformations to the new image and save it in image subdir\n",
    "        \"\"\"\n",
    "        # x_train = self.read_images(join(training_filepath, \"images\"))\n",
    "        # y_train = self.read_labels(training_filepath)\n",
    "        # x_train = self.read_images(self.training_images_filepath)\n",
    "        y_train = self.read_labels(self.training_labels_filepath)\n",
    "    \n",
    "        # print(f'x_train: {len(x_train)}')\n",
    "        print(f'y_train: {len(y_train)}')\n",
    "\n",
    "        # minority_cat = y_train[y_train[1] == \"true\"]\n",
    "        minority_cat = [el for el in y_train if el == 1]\n",
    "        # majority_cat = y_train[y_train[1] == \"false\"]\n",
    "        majority_cat = [el for el in y_train if el == 0]\n",
    "\n",
    "\n",
    "        print(f'minority_cat: {len(minority_cat)}')\n",
    "        print(f'majority_cat: {len(majority_cat)}')\n",
    "        print(f'Need to make {len(majority_cat)/len(minority_cat)} duplicates of each minority case')\n",
    "\n",
    "        theta = -15\n",
    "        for image in training_set:\n",
    "            if len(minority_cat) < len(majority_cat):\n",
    "                break\n",
    "\n",
    "            for i in range(48):\n",
    "                transform, theta = self.return_transform(iter, theta)\n",
    "                # Iterate over each item in the array\n",
    "                for call in transform:\n",
    "                    try:\n",
    "                        # Execute the function call using exec()\n",
    "                        _image = exec(call, image)\n",
    "                    except Exception as e:\n",
    "                        print('Error executing function:', e)\n",
    "\n",
    "            # \n",
    "\n",
    "    def return_transform(iter, theta):\n",
    "        transform = []\n",
    "        if iter%2 == 1:\n",
    "            transform.append(\"mirror()\")\n",
    "        if iter%2 == 0:\n",
    "            theta += 15\n",
    "        theta %= 360\n",
    "        transform.append(f\"rotate({theta})\")\n",
    "\n",
    "        return transform, theta\n",
    "\n",
    "    def return_transform(iter, theta):\n",
    "        transform = []\n",
    "        if iter%2 == 1:\n",
    "            transform.append(\"mirror()\")\n",
    "        theta += 15\n",
    "        theta %= 360\n",
    "        transform.append(f\"rotate({theta})\")\n",
    "\n",
    "        return transform, theta\n",
    "\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train = self.read_images(self.training_images_filepath)\n",
    "        y_train = self.read_labels(self.training_labels_filepath)\n",
    "        x_test = self.read_images(self.training_images_filepath)\n",
    "        y_test = self.read_labels(self.training_labels_filepath)\n",
    "\n",
    "          # Convert data to NumPy arrays\n",
    "        x_train = np.array(x_train)\n",
    "        y_train = np.array(y_train)\n",
    "        x_test = np.array(x_test)\n",
    "        y_test = np.array(y_test)\n",
    "        \n",
    "        return (x_train, y_train),(x_test, y_test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: 4484\n",
      "minority_cat: 94\n",
      "majority_cat: 4390\n",
      "Need to make 46.702127659574465 duplicates of each minority case\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set file paths based on added MNIST Datasets``\n",
    "input_path = 'data'\n",
    "training_images_filepath = join(input_path, join('training_nih', 'images'))\n",
    "training_labels_filepath = join(input_path, join('training_nih', 'emph_labels.csv'))\n",
    "test_images_filepath = join(input_path, join('test_nih', 'images'))\n",
    "test_labels_filepath = join(input_path, join('test_nih', 'emph_labels.csv'))\n",
    "\n",
    "# Load MINST dataset\n",
    "nih_dataloader = NIHDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "nih_dataloader.augmented_training_images(join('data','training_nih','images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rotate(0)']\n",
      "['mirror()', 'rotate(0)']\n",
      "['rotate(15)']\n",
      "['mirror()', 'rotate(15)']\n",
      "['rotate(30)']\n",
      "['mirror()', 'rotate(30)']\n",
      "['rotate(45)']\n",
      "['mirror()', 'rotate(45)']\n",
      "['rotate(60)']\n",
      "['mirror()', 'rotate(60)']\n",
      "['rotate(75)']\n",
      "['mirror()', 'rotate(75)']\n",
      "['rotate(90)']\n",
      "['mirror()', 'rotate(90)']\n",
      "['rotate(105)']\n",
      "['mirror()', 'rotate(105)']\n",
      "['rotate(120)']\n",
      "['mirror()', 'rotate(120)']\n",
      "['rotate(135)']\n",
      "['mirror()', 'rotate(135)']\n",
      "['rotate(150)']\n",
      "['mirror()', 'rotate(150)']\n",
      "['rotate(165)']\n",
      "['mirror()', 'rotate(165)']\n",
      "['rotate(180)']\n",
      "['mirror()', 'rotate(180)']\n",
      "['rotate(195)']\n",
      "['mirror()', 'rotate(195)']\n",
      "['rotate(210)']\n",
      "['mirror()', 'rotate(210)']\n",
      "['rotate(225)']\n",
      "['mirror()', 'rotate(225)']\n",
      "['rotate(240)']\n",
      "['mirror()', 'rotate(240)']\n",
      "['rotate(255)']\n",
      "['mirror()', 'rotate(255)']\n",
      "['rotate(270)']\n",
      "['mirror()', 'rotate(270)']\n",
      "['rotate(285)']\n",
      "['mirror()', 'rotate(285)']\n",
      "['rotate(300)']\n",
      "['mirror()', 'rotate(300)']\n",
      "['rotate(315)']\n",
      "['mirror()', 'rotate(315)']\n",
      "['rotate(330)']\n",
      "['mirror()', 'rotate(330)']\n",
      "['rotate(345)']\n",
      "['mirror()', 'rotate(345)']\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)\n",
    "\n",
    "def return_transform(iter, theta):\n",
    "    transform = []\n",
    "    if iter%2 == 1:\n",
    "        transform.append(\"mirror()\")\n",
    "    if iter%2 == 0:\n",
    "        theta += 15\n",
    "    theta %= 360\n",
    "    transform.append(f\"rotate({theta})\")\n",
    "\n",
    "    return transform, theta\n",
    "\n",
    "theta = -15\n",
    "for i in range(48):\n",
    "    transform, theta = return_transform(i, theta)\n",
    "    print(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate and translate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "images = []\n",
    "                \n",
    "# Get the list of image file paths in the directory\n",
    "image_paths = glob.glob(os.path.join(images_filepath, \"*.png\"))\n",
    "\n",
    "# Iterate over each image path\n",
    "for image_path in image_paths:\n",
    "    image = Image.open(image_path)\n",
    "    resized_image = image.resize((512, 512))\n",
    "    grayscale_image = resized_image.convert(\"L\")\n",
    "    # array = np.array(grayscale_image).astype(float)\n",
    "    array = np.array(grayscale_image).astype(np.float16)\n",
    "\n",
    "    images.append(array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest data and map labels to categorical data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from array import array\n",
    "\n",
    "\n",
    "# MNIST Data Loader Class\n",
    "class NIHDataloader(object):\n",
    "    def __init__(self, \n",
    "                training_images_filepath,\n",
    "                training_labels_filepath,\n",
    "                test_images_filepath, \n",
    "                test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "\n",
    "    def read_labels(self, labels_filepath):        \n",
    "        labels = []\n",
    "        images = []\n",
    "        \n",
    "        with open(labels_filepath, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            labels = array(\"B\", [1 if row[1]==\"true\" else 0 for row in reader])   \n",
    "        \n",
    "        return labels\n",
    "\n",
    "    def read_images(self, images_filepath):        \n",
    "        labels = []\n",
    "        images = []\n",
    "                        \n",
    "        # Get the list of image file paths in the directory\n",
    "        image_paths = glob.glob(os.path.join(images_filepath, \"*.png\"))\n",
    "\n",
    "        # Iterate over each image path\n",
    "        for image_path in image_paths:\n",
    "            image = Image.open(image_path)\n",
    "            resized_image = image.resize((512, 512))\n",
    "            grayscale_image = resized_image.convert(\"L\")\n",
    "            # array = np.array(grayscale_image).astype(float)\n",
    "            array = np.array(grayscale_image).astype(np.float16)\n",
    "\n",
    "            images.append(array)\n",
    "\n",
    "        return images\n",
    "        \n",
    "    def augmented_training_images(self, training_filepath: str):\n",
    "        \"\"\"\n",
    "        Function to augment minority category of training data to be of equal size to majority category\n",
    "\n",
    "        Steps: \n",
    "            - ingest training images and labels from new data subdir\n",
    "            for each image in training set (while len(cat A)<len(cat B))\n",
    "            - create new unique id\n",
    "            - write row to label csv\n",
    "            - apply one of a set of transformations to the new image and save it in image subdir\n",
    "        \"\"\"\n",
    "        # x_train = self.read_images(join(training_filepath, \"images\"))\n",
    "        # y_train = self.read_labels(training_filepath)\n",
    "        # x_train = self.read_images(self.training_images_filepath)\n",
    "        y_train = self.read_labels(self.training_labels_filepath)\n",
    "    \n",
    "        # print(f'x_train: {len(x_train)}')\n",
    "        print(f'y_train: {len(y_train)}')\n",
    "\n",
    "        # minority_cat = y_train[y_train[1] == \"true\"]\n",
    "        minority_cat = [el for el in y_train if el == 1]\n",
    "        # majority_cat = y_train[y_train[1] == \"false\"]\n",
    "        majority_cat = [el for el in y_train if el == 0]\n",
    "\n",
    "\n",
    "        print(f'minority_cat: {len(minority_cat)}')\n",
    "        print(f'majority_cat: {len(majority_cat)}')\n",
    "        print(f'Need to make {len(majority_cat)/len(minority_cat)} duplicates of each minority case')\n",
    "\n",
    "        transformations = {\n",
    "            'rot_1': rotate(270),\n",
    "            'mirror': mirror()\n",
    "        \n",
    "        }\n",
    "        while len(minority_cat) < len(majority_cat):\n",
    "            self.return_transform(iter)\n",
    "\n",
    "        #     if len(minority_cat) < len(majority_cat):\n",
    "        #         break\n",
    "        #     # generate a new image id that does not exist in training dataset\n",
    "        #     new_id = random_id_not_in_images()\n",
    "            \n",
    "        #     # make a copy of the current image row in csv with the new id\n",
    "        #     write_row_to_csv()\n",
    "\n",
    "            \n",
    "\n",
    "        #     # \n",
    "\n",
    "    def return_transform(iter):\n",
    "        transform = []\n",
    "        if iter%2 == 1:\n",
    "            transform.append(\"mirror()\")\n",
    "        theta += 15\n",
    "        transform.append(f\"rotate({theta})\")\n",
    "\n",
    "        return transform\n",
    "\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train = self.read_images(self.training_images_filepath)\n",
    "        y_train = self.read_labels(self.training_labels_filepath)\n",
    "        x_test = self.read_images(self.training_images_filepath)\n",
    "        y_test = self.read_labels(self.training_labels_filepath)\n",
    "\n",
    "          # Convert data to NumPy arrays\n",
    "        x_train = np.array(x_train)\n",
    "        y_train = np.array(y_train)\n",
    "        x_test = np.array(x_test)\n",
    "        y_test = np.array(y_test)\n",
    "        \n",
    "        return (x_train, y_train),(x_test, y_test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from array import array\n",
    "\n",
    "\n",
    "# MNIST Data Loader Class\n",
    "class NIHDataloader(object):\n",
    "    def __init__(self, \n",
    "                training_images_filepath,\n",
    "                training_labels_filepath,\n",
    "                test_images_filepath, \n",
    "                test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "\n",
    "    def read_labels(self, labels_filepath):        \n",
    "        labels = []\n",
    "        images = []\n",
    "        \n",
    "        with open(labels_filepath, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            labels = array(\"B\", [1 if row[1]==\"true\" else 0 for row in reader])   \n",
    "        \n",
    "        return labels\n",
    "\n",
    "    def read_images(self, images_filepath):        \n",
    "        labels = []\n",
    "        images = []\n",
    "                        \n",
    "        # Get the list of image file paths in the directory\n",
    "        image_paths = glob.glob(os.path.join(images_filepath, \"*.png\"))\n",
    "\n",
    "        # Iterate over each image path\n",
    "        for image_path in image_paths:\n",
    "            image = Image.open(image_path)\n",
    "            resized_image = image.resize((512, 512))\n",
    "            grayscale_image = resized_image.convert(\"L\")\n",
    "            # array = np.array(grayscale_image).astype(float)\n",
    "            array = np.array(grayscale_image).astype(np.float16)\n",
    "\n",
    "            images.append(array)\n",
    "\n",
    "        return images\n",
    "        \n",
    "    def augmented_training_images(self, training_filepath: str):\n",
    "        \"\"\"\n",
    "        Function to augment minority category of training data to be of equal size to majority category\n",
    "\n",
    "        Steps: \n",
    "            - ingest training images and labels from new data subdir\n",
    "            for each image in training set (while len(cat A)<len(cat B))\n",
    "            - create new unique id\n",
    "            - write row to label csv\n",
    "            - apply one of a set of transformations to the new image and save it in image subdir\n",
    "        \"\"\"\n",
    "        # x_train = self.read_images(join(training_filepath, \"images\"))\n",
    "        # y_train = self.read_labels(training_filepath)\n",
    "        # x_train = self.read_images(self.training_images_filepath)\n",
    "        y_train = self.read_labels(self.training_labels_filepath)\n",
    "    \n",
    "        # print(f'x_train: {len(x_train)}')\n",
    "        print(f'y_train: {len(y_train)}')\n",
    "\n",
    "        # minority_cat = y_train[y_train[1] == \"true\"]\n",
    "        minority_cat = [el for el in y_train if el == 1]\n",
    "        # majority_cat = y_train[y_train[1] == \"false\"]\n",
    "        majority_cat = [el for el in y_train if el == 0]\n",
    "\n",
    "\n",
    "        print(f'minority_cat: {len(minority_cat)}')\n",
    "        print(f'majority_cat: {len(majority_cat)}')\n",
    "        print(f'Need to make {len(majority_cat)/len(minority_cat)} duplicates of each minority case')\n",
    "\n",
    "        transformations = {\n",
    "            'rot_1': rotate(270),\n",
    "            'mirror': mirror()\n",
    "        \n",
    "        }\n",
    "        while len(minority_cat) < len(majority_cat):\n",
    "            self.return_transform(iter)\n",
    "\n",
    "        #     if len(minority_cat) < len(majority_cat):\n",
    "        #         break\n",
    "        #     # generate a new image id that does not exist in training dataset\n",
    "        #     new_id = random_id_not_in_images()\n",
    "            \n",
    "        #     # make a copy of the current image row in csv with the new id\n",
    "        #     write_row_to_csv()\n",
    "\n",
    "            \n",
    "\n",
    "        #     # \n",
    "\n",
    "    def return_transform(iter):\n",
    "        transform = []\n",
    "        if iter%2 == 1:\n",
    "            transform.append(\"mirror()\")\n",
    "        theta += 15\n",
    "        transform.append(f\"rotate({theta})\")\n",
    "\n",
    "        return transform\n",
    "\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train = self.read_images(self.training_images_filepath)\n",
    "        y_train = self.read_labels(self.training_labels_filepath)\n",
    "        x_test = self.read_images(self.training_images_filepath)\n",
    "        y_test = self.read_labels(self.training_labels_filepath)\n",
    "\n",
    "          # Convert data to NumPy arrays\n",
    "        x_train = np.array(x_train)\n",
    "        y_train = np.array(y_train)\n",
    "        x_test = np.array(x_test)\n",
    "        y_test = np.array(y_test)\n",
    "        \n",
    "        return (x_train, y_train),(x_test, y_test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data\n",
      "mapped y data to categorical\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = nih_dataloader.load_data()\n",
    "print('loaded data')\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "print('mapped y data to categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: [[ 85.  85.  84. ...   5.   5.   5.]\n",
      " [ 84.  84.  83. ...   5.   5.   5.]\n",
      " [ 80.  79.  79. ...   5.   5.   5.]\n",
      " ...\n",
      " [120. 122. 131. ...   7.   2.   2.]\n",
      " [115. 119. 129. ...   5.   3.   4.]\n",
      " [ 40.  41.  43. ...   3.   3.   3.]]\n",
      "y_train: [1. 0.]\n",
      "x_test: [[ 85.  85.  84. ...   5.   5.   5.]\n",
      " [ 84.  84.  83. ...   5.   5.   5.]\n",
      " [ 80.  79.  79. ...   5.   5.   5.]\n",
      " ...\n",
      " [120. 122. 131. ...   7.   2.   2.]\n",
      " [115. 119. 129. ...   5.   3.   4.]\n",
      " [ 40.  41.  43. ...   3.   3.   3.]]\n",
      "y_test: [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train: {x_train[0]}')\n",
    "print(f'y_train: {y_train[0]}')\n",
    "print(f'x_test: {x_test[0]}')\n",
    "print(f'y_test: {y_test[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 510, 510, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 255, 255, 32)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 253, 253, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 126, 126, 64)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 124, 124, 64)      36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55744 (217.75 KB)\n",
      "Trainable params: 55744 (217.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "model.summary(): None\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 510, 510, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 255, 255, 32)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 253, 253, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 126, 126, 64)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 124, 124, 64)      36928     \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 984064)            0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                62980160  \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63036034 (240.46 MB)\n",
      "Trainable params: 63036034 (240.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "model.summary(): None\n",
      "compiled model\n"
     ]
    }
   ],
   "source": [
    "model = compile_model(0.005)\n",
    "print('compiled model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "  2/141 [..............................] - ETA: 12:37 - loss: 0.0818 - accuracy: 0.9844"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history, precision, recall, f1 \u001b[39m=\u001b[39m train_model(x_train, y_train, x_test, y_test, model, \u001b[39m32\u001b[39;49m, \u001b[39m32\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtrain model\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[54], line 41\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(X_train, Y_train, X_test, Y_test, model, epochs, batch_size)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(X_train, Y_train, X_test, Y_test, model, epochs, batch_size):\n\u001b[1;32m---> 41\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[0;32m     43\u001b[0m     \u001b[39m# Predict on test set\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history, precision, recall, f1 = train_model(x_train, y_train, x_test, y_test, model, 32, 32)\n",
    "print('train model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0578 - accuracy: 0.9906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 14:47:06.280 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\ShaneShort\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyse training\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = analyse_history(model, history, x_test, y_test)\n",
    "print('analyse training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model against individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 207ms/step\n",
      "Prediction: 8\n",
      "True Label: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def _test_single(X_test, Y_test, image_index):\n",
    "    image = X_test[image_index]  # Get the corresponding image data from X_test\n",
    "    label = Y_test[image_index]  # Get the corresponding label data from y_test\n",
    "\n",
    "    image = image.reshape(28, 28)  # Reshape the image array from (28, 28, 1) to (28, 28)\n",
    "\n",
    "    plt.imshow(image, cmap='gray')  # Display the image using grayscale color map\n",
    "    plt.title(f\"Label: {np.argmax(label)}\")  # Set the title of the plot with the true label\n",
    "    plt.axis('off')  # Remove the axis labels\n",
    "\n",
    "    return plt.gcf()  # Return the current figure for later plotting\n",
    "\n",
    "image_index = random.randint(0, len(x_test)-1)  # Generate a random index within the range of the test set\n",
    "label = y_test[image_index]  # Get the corresponding label data from y_test\n",
    "prediction = model.predict(np.expand_dims(x_test[image_index], axis=0))\n",
    "predicted_label = np.argmax(prediction)\n",
    "\n",
    "print(\"Prediction:\", predicted_label)\n",
    "print(\"True Label:\", np.argmax(label))\n",
    "\n",
    "figure = _test_single(x_test, y_test, image_index)\n",
    "plt.show()  # Show the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window = tk.Tk()\n",
    "canvas = tk.Canvas(window, width=280, height=280, bg='white')\n",
    "canvas.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_mouse_drag(event):\n",
    "    x = event.x\n",
    "    y = event.y\n",
    "    radius = 5\n",
    "    canvas.create_oval(x - radius, y - radius, x + radius, y + radius, fill='black')\n",
    "\n",
    "canvas.bind('<B1-Motion>', on_mouse_drag)\n",
    "def clear_canvas():\n",
    "    canvas.delete('all')\n",
    "\n",
    "def run_model_prediction():\n",
    "    image = canvas.postscript(colormode='gray')\n",
    "    img = Image.open(io.BytesIO(image.encode('utf-8')))\n",
    "    img = img.resize((28, 28))\n",
    "    # Process the image and feed it into your model for prediction\n",
    "    prediction = model.predict(np.expand_dims(img, axis=0))\n",
    "    predicted_label = np.argmax(prediction)\n",
    "\n",
    "    print(\"Prediction:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ShaneShort\\AppData\\Local\\Temp\\ipykernel_9444\\1246062621.py\", line 14, in run_model_prediction\n",
      "    img = img.resize((28, 28))\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\PIL\\Image.py\", line 2157, in resize\n",
      "    self.load()\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\PIL\\EpsImagePlugin.py\", line 387, in load\n",
      "    self.im = Ghostscript(self.tile, self.size, self.fp, scale, transparency)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\PIL\\EpsImagePlugin.py\", line 138, in Ghostscript\n",
      "    raise OSError(msg)\n",
      "OSError: Unable to locate Ghostscript on paths\n"
     ]
    }
   ],
   "source": [
    "clear_button = tk.Button(window, text='Clear', command=clear_canvas)\n",
    "clear_button.pack()\n",
    "\n",
    "predict_button = tk.Button(window, text='Predict', command=run_model_prediction)\n",
    "predict_button.pack()\n",
    "\n",
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
